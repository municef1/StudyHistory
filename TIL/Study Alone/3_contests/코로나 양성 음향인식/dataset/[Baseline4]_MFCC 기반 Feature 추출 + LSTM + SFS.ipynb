{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffc0fb5-5918-4ed2-8374-0c6513a267a2",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd23f502-45c6-43a5-92a2-c5b9735449ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import datetime as dt\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "###\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d6491",
   "metadata": {},
   "source": [
    "# LSTM + sequential forward selection(SFS) 적용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17027eb2-ab83-450b-97d0-28dff9cb2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SR':16000,     # 고정시킬거임\n",
    "    'N_MFCC':32,    # MFCC 벡터를 추출할 개수 조정할지도 모름\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "'''\n",
    "① sr\n",
    "\n",
    "sampling rate를 말합니다. default값은 22050Hz입니다. 음성 데이터를 load 할 때 sr을 16000Hz으로 하면 꼭 sr=16000을 파라미터로 삽입해야 합니다. (사람의 목소리는 대부분 16000Hz 안에 포함된다고 합니다)\n",
    "\n",
    "② n_mfcc\n",
    "\n",
    "return 될 mfcc의 개수를 정해주는 파라미터입니다. default값은 20입니다. 더 다양한 데이터 특징을 추출하기 위해서는 100까지 증가 시키기도 합니다.\n",
    "\n",
    "③ n_fft\n",
    "\n",
    "frame의 length를 결정하는 파라미터 입니다. n_fft를 설정하면 window size가 자동으로 같은 값으로 설정되는데 window size의 크기로 잘린 음성이 n_fft보다 작은 경우 0으로 padding을 붙여주는 작업을 하기 때문에 n_fft는 window size보다 크거나 같아야 합니다. \n",
    "\n",
    "일반적으로 자연어 처리에서는 음성을 25m의 크기를 기본으로 하고 있으며 16000Hz인 음성에서는 400에 해당하는 값입니다. (16000 * 0.025 = 400) 즉, n_fft는 sr에 frame_length인 0.025를 곱한 값입니다.\n",
    "\n",
    "④ hop_length\n",
    "\n",
    "hop_length의 길이만큼 옆으로 가면서 데이터를 읽습니다. 10ms를 기본으로 하고 있어 16000Hz인 음성에서는 160에 해당합니다. (16000 * 0.01 = 160) 즉, hop_length는 sr에 frame_stride인 0.01를 곱해서 구할 수 있습니다.\n",
    "\n",
    "window_length가 0.025이고 frame_stride가 0.01이라고 하면 0.015초씩은 데이터를 겹치면서 읽는다고 생각하면 됩니다.\n",
    "\n",
    "내용 출처 : https://youdaeng-com.tistory.com/5\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8abaa4-229d-4ce9-a737-3263fc9c6213",
   "metadata": {},
   "source": [
    "## Fixed Random-Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a75c6-42e9-4a60-8ca2-b70df1248871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d57a51-dc27-4af5-9261-91f61194d975",
   "metadata": {},
   "source": [
    "## Data Pre-Processing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da03dd7-888b-44f2-80ae-cb28fd091de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train_data.csv')\n",
    "test_df = pd.read_csv('./test_data.csv')\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247202fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345b255",
   "metadata": {},
   "source": [
    "#### 30개 파일들을 직접 듣고 대략적으로 어떤 느낌인지 들어보자\n",
    "#### . . .\n",
    "#### 전혀 모르겠다. 안 걸린 녀석이 걸린 녀석처럼 기침한다...\n",
    "#### 이게 가능한 주제일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94685e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb58d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['covid19']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa96315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['covid19']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601f0b0-6d28-48de-88d3-3c68d43ad2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_feature(df, data_type, save_path):\n",
    "    # Data Folder path\n",
    "    root_folder = './wav_dataset' \n",
    "    if os.path.exists(save_path):\n",
    "        print(f'{save_path} is exist.')\n",
    "        return\n",
    "    features = []\n",
    "    for uid in tqdm(df['id']):\n",
    "        root_path = os.path.join(root_folder, data_type)\n",
    "        path = os.path.join(root_path, str(uid).zfill(5)+'.wav')\n",
    "\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "        \n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\n",
    "                                                                                '''\n",
    "                                                                                MFCC(Mel-Frequency Cepstral Coefficient)\n",
    "                                                                                - 멜 스펙트럼에서 켑스트럴 분석을 통해 추출된 값이다.\n",
    "                                                                                    - Cepstral은 스펙트럼에서 배음 구조를 유추할 수 있도록 도와주는 분석이다.\n",
    "                                                                                - 로그 멜 스펙트럼에 역푸리에변환(Inverse Fourier Transform)을 적용한다.\n",
    "                                                                                    - 주파수 정보의 상관 관계가 높은 문제를 해소한다.\n",
    "                                                                                '''\n",
    "        \n",
    "        y_feature = []\n",
    "        # 추출된 MFCC들의 평균을 Feature로 사용\n",
    "        for e in mfcc:\n",
    "            y_feature.append(np.mean(e))\n",
    "        features.append(y_feature)\n",
    "    \n",
    "    # 기존의 자가진단 정보를 담은 데이터프레임에 추출된 오디오 Feature를 추가\n",
    "    mfcc_df = pd.DataFrame(features, columns=['mfcc_'+str(x) for x in range(1,CFG['N_MFCC']+1)])\n",
    "    df = pd.concat([df, mfcc_df], axis=1)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5713d-4bff-4598-bbfd-5cfb1b3109ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mfcc_feature(train_df, 'train', './train_mfcc_data.csv')\n",
    "get_mfcc_feature(test_df, 'test', './test_mfcc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82307fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998e196-6a3b-4214-8495-f026c015f8c5",
   "metadata": {},
   "source": [
    "## Data Pre-Processing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896cce2-0f47-4377-b2a1-95144e58581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav 파일의 MFCC Feature와 상태정보를 합친 학습데이터를 불러옵니다.\n",
    "train_df = pd.read_csv('./train_mfcc_data.csv')\n",
    "\n",
    "# 학습데이터를 모델의 input으로 들어갈 x와 label로 사용할 y로 분할\n",
    "train_x = train_df.drop(columns=['id', 'covid19'])\n",
    "train_y = train_df['covid19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a66ac7-c6db-4258-802a-9fedded85412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoding(ohe, x):\n",
    "    # 학습데이터로 부터 fit된 one-hot encoder (ohe)를 받아 transform 시켜주는 함수\n",
    "    encoded = ohe.transform(x['gender'].values.reshape(-1,1))\n",
    "    encoded_df = pd.DataFrame(encoded, columns=ohe.categories_[0])\n",
    "    x = pd.concat([x.drop(columns=['gender']), encoded_df], axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade4609-22a8-40f1-936d-a8ec8ba90f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'gender' column의 경우 추가 전처리가 필요 -> OneHotEncoder 적용\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(train_x['gender'].values.reshape(-1,1))\n",
    "train_x = onehot_encoding(ohe, train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44c2fb-1560-4c8a-a908-9fa9271f5e03",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646f9d2-a911-4ad7-83f3-1a5b79cb5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(random_state=CFG['SEED']) # Sklearn에서 제공하는 Multi-layer Perceptron classifier 사용\n",
    "model.fit(train_x, train_y) # Model Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ec15f-5fc9-480b-9c9b-bcbf68ee34ed",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf251c2-6cba-446f-ab6c-45236eec93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 학습데이터를 전처리한 과정과 동일하게 test data에도 적용\n",
    "test_x = pd.read_csv('./test_mfcc_data.csv')\n",
    "test_x = test_x.drop(columns=['id'])\n",
    "# Data Leakage에 유의하여 train data로만 학습된 ohe를 사용\n",
    "test_x = onehot_encoding(ohe, test_x)\n",
    "\n",
    "# Model 추론\n",
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8585466-800b-4125-8289-5dce5070990c",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e91fa6-ef2c-418f-90f2-e5662abe51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['covid19'] = preds\n",
    "submission.to_csv('submit2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_now = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee95a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.timedelta(weeks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c11e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2182ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f1d60650da460e3a71bb0bcfad019a9fb831b1a41328969b088bceb26ffbac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
