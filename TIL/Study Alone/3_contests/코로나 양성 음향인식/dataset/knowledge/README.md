# 소리란?

- 공기나 물 같은 매질의 진동을 통해 전달되는 종파
- 사람의 귀에 들려오는 소리는 공기 속을 전해오는 파동
- 소리의 3요소
  - 세기(소리의 크기)
  - 높낮이(소리의 높고 낮음)
  - 음색(소리의 색상)
- 소리의 주파수(Hz) 원리
  - 낮은 음일수록 주파수가 낮다.
  - 높은 음일수록 주파수가 높다

- 진폭, 주기, 파장의 길이가 시간축에 따라서 파동으로 나타난다.

# 소리의 샘플링 레이트(sampling rate) 과정
- 소리를 컴퓨터에 입력시키기 위해 음파를 숫자로 바꿔야 함
- 샘플링 레이트는 우리가 듣는 소리(아날로그)를 숫자화(디지털로 변환)시킨 것이다.
- 표준 Sampling rate는 44.1kHz이다.
  - 1초당 44100개의 샘플을 추출했다는 것을 의미한다.

# 특징 추출(Feature extraction)
- 파동은 시간 영역(Time domain)과 주파수 영역(Frequency domain)으로 구성된다.
- 소리 특성 정보를 추출하기 위한 다양한 특징 추출방법이 존재한다.
  - 스펙트럼, 스펙트로그램, 사클로그램, MFCC 등

## 스펙트럼
- 파동의 시간 영역을 주파수 영역으로 변환한다.
- 음향 신호를 주파수, 진폭으로 분석하여 보여준다
- 고속 푸리에 변환을 적용한다.
- x축은 주파수, y축은 진폭을 나타낸다.

## 멜 스펙토그램
- 주파수 특성이 시간에 따라 달라지는 오디오를 분석하기 위한 특징 추출 기법이다.
- 인간의 청각 영역을 반영한 mel scale을 적용한다.
  - 보통 고주파로 갈수록 사람이 구분하는 주파수 간격이 넓어지는데 이를 반영해준다.
- 프레임의 길이와 슬라이딩 범위를 하이퍼 파라미터로 설정한다.
  
## MFCC(Mel-Frequency Cepstral Coefficient)
- 멜 스펙트럼에서 켑스트럴 분석을 통해 추출된 값이다.
  - Cepstral은 스펙트럼에서 배음 구조를 유추할 수 있도록 도와주는 분석이다.
- 로그 멜 스펙트럼에 역푸리에변환(Inverse Fourier Transform)을 적용한다.
  - 주파수 정보의 상관 관계가 높은 문제를 해소한다.
  

# Librosa 패키지
- 오디오 신호를 분석하는 python 모듈이다.
- 오디오 데이터 입출력 및 다양한 특징 추출 방법론을 쉽게 사용할 수 있다.
- 오디오 데이터로 추출된 특징의 시각화 기능을 제공한다.

# 추출된 특징 사용
- 고차원 특징이기에 머신러닝 모델 적용을 위해 기술통계량을 사용한다.
  - 평균, 절사평균, 중위수, 최빈수, 최솟값, 최댓값, 분산, 표준편차, 절대편차...
- 최근 딥러닝 모델에서는 특징 고유의 값이나 히트맵을 이미지로 변환하여 사용한다.

# 데이터 증강 기법(Data Augmentation)
- 일반적으로 레이블이 존재하는 데이터에 변화를 주어 원본 데이터와 같은 레이블을 갖는 새로운 데이터를 만드는 기법
  - 좌우 반전 / 이미지 자르기 / 이미지 회전 / 밝기 조절 등
  - (중요!) 이미지화 된 소리데이터는 좌우반전, 이미지 자르기 등을 해버리면 이상한 소리가 되어버리기 때문에 다른 방법이 필요하다!!!!

- Adding noise : white noise를 추가하여 원본 오디오에 잡음을 생성한다.
- Shifting : 원본 오디오 데이터를 좌우로 이동한다. 123456789 > 5678912345 순서로 바꾸는 등
- Stretching : 원본 오디오 데이터의 빠르기를 조정한다. 3초 짜리 소리를 7초로 늘린다. 너무 빠르거나 느리게하면 그 소리만의 특색이 사라질 수 있다.

# 소리 데이터를 위한 딥러닝 모델
- 2016년 구글 딥마인드에서 오디오 생성 모델인 wavenet 공개
- 텍스트를 음성으로 변환하는 TTS 수행하기에 적합한 딥러닝 모델이다.
  - 당시 TTS 모델들은 많은 양의 데이털르 필요로 하고 부자연스렁누 음성이 생성되었다고 한다.

## Wavenet
- 오디오의 파형 형태를 직접 사용해서 새로운 파형을 생성하는 확률론적 모델이다.
- 30개의 residual block을 쌓은 형태의 구조를 보인다.
- 주요 특징 3가지
  - 음성 파형 학습을 위한 새로운 구조를 제시한다.
  - 조건부 모델링을 이용해 특징적인 음성을 생성할 수 있다.
  - 오디오 파형만을 이용해 자연스럽고 새로운 음성 파형을 생성할 수 있다.

### SoftMax 함수
- Wavenet 입출력은 아날로그 음성 데이터를 변환한 디지털 데이터 값이다.
- 오디오는 16비트의 정수 값으로 저장해서 사용하기에 확률론적 모델링이 힘들다.
  - 매 시점마다 2의 15승~ 2의 15승 + 1 사이의 숫자가 나온다.
  - t 시점에 특정 파형이 나올 확률을 계산하는데 총 65,536개의 확률을 고려한다.
- 뮤-law companding 변환을 통해 작은 정수 범위로 총 256개의 확률을 고려한다.

### Dilated Casual Convolusions
- Dilated convolution과 Casual convolution 개념을 결합한 컨볼루션 연산이다.
- Dilated convolution은 필터에 zero padding을 추가해 모델의 receptive field를 늘려준다.
  - receptive field란 필터가 한 번에 볼 수 있는 데이터를 탐색할 수 있는 영역이다.
  - 입력된 데이터의 특징을 잡아내기 위해서는 receptive field는 높으면 높을수록 좋다.
- Causal convolutions는 시간 순서를 고려하여 필터를 적용하는 컨볼루션 연산이다.
  - RNN 계열의 모델처럼 시계열 데이터를 모델링할 수 있다.
  - Receptive field를 넓히기 위해서 많은 양의 레이어를 쌓아야 한다는 단점이 존재한다.
- Dilation 기법을 이용해 일전 스텝을 건너뛰며 필터를 적용하는 dilated causal convolution
- 적은 층의 레이어로 receptive field를 넓힐 수 있는 효과를 가져온다.
- 논문에서는 dilation 크기를 2배씩 증가시키고 이를 반복한다.
  - 1,2,4, ..., 512, 1, 2, 4, ..., 512

- 이 개념 이해한거 요약) 512개를 256개, 256개를 128개, 64개, ... 2개를 1개로 만들면 만들어진 1개를 다시 밑에 넣고 512개를 또 256개,,, 이렇게 반복해서 만들어나간다....?

### Conditional wavenet
- 확률 모델에 조건 정보를 추가함으로써 특정한 성질을 가진 오디오를 생성할 수 있다.
- 조건부 모델링 방법 2가지
  - 전역적 조건 : 시점 변화에 영향을 받지 않는 정보를 추가한다.
    - 안녕하세요, 아이고 배고프다, 반갑습니다! > 화자 고유의 음성을 생성
  - 지역적 조건 : 시점 변화에 영향을 받는 정보를 추가한다.
    아이고(특유의 말투, 음성정보) 배고프다 > 특정 텍스트에 맞는 음성을 생성

### Generated Audio by wavenet
- 기존 TTS 방법론의 부자연스러운 음성과 달리 자연스러운 음성을 생성한다.
- 화자의 음성 정보를 조건부 정보로 활용하여 다양한 음색의 음성을 생성한다.
  - 화자의 고유 음성 identity를 조건부로 써서 다양하게 출력되게 해준다는 뜻이다!!

Reference 

1. Oord, A. V. D., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). Wavenet: A generative model for raw audio. arXiv preprint arXiv:1609.03499.

 

2. Mehri, S., Kumar, K., Gulrajani, I., Kumar, R., Jain, S., Sotelo, J., ... & Bengio, Y. (2016). SampleRNN: An unconditional end-to-end neural audio generation model. arXiv preprint arXiv:1612.07837.

 

3. Suh, S., Park, S., Jeong, Y., & Lee, T. (2020). Designing acoustic scene classification models with CNN variants. DCASE2020 Challenge, Tech. Rep






# 아이디어...
- 불량품이 나오는 부품의 소리를 알아내는데도 쓴다고 한다.
- 어? 우린 주변에 수박 두드려서 품질 보는 아주머니들도 있다
- 수박 두드려서 당도측정이 될까?!?! 재밌겠다!